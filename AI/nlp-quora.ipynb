{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b4e496-d516-43a8-aa5b-34053a117efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11be0584-4044-4056-a006-3a4a217967d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('quora_train_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437f46c4-a91e-45f1-b306-5a362c20bcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>781152</td>\n",
       "      <td>990588f6dfebf5a8161e</td>\n",
       "      <td>Why is Trump in trouble for the \"shithole\" rem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147077</td>\n",
       "      <td>1cc35afd2b752c94cde6</td>\n",
       "      <td>Would I have a chance of getting an internship...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>690610</td>\n",
       "      <td>8742ebb59f819cbcf308</td>\n",
       "      <td>Do students at schools like Princeton, Columbi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173444</td>\n",
       "      <td>21eac90fbe362155ea06</td>\n",
       "      <td>Where can I get quick notifications about UPSC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27301</td>\n",
       "      <td>0559366f2e08fc9e8432</td>\n",
       "      <td>How is the job security right now of BTA, join...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   qid  \\\n",
       "0      781152  990588f6dfebf5a8161e   \n",
       "1      147077  1cc35afd2b752c94cde6   \n",
       "2      690610  8742ebb59f819cbcf308   \n",
       "3      173444  21eac90fbe362155ea06   \n",
       "4       27301  0559366f2e08fc9e8432   \n",
       "\n",
       "                                       question_text  target  \n",
       "0  Why is Trump in trouble for the \"shithole\" rem...       1  \n",
       "1  Would I have a chance of getting an internship...       0  \n",
       "2  Do students at schools like Princeton, Columbi...       0  \n",
       "3  Where can I get quick notifications about UPSC...       0  \n",
       "4  How is the job security right now of BTA, join...       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "821b21f5-cd29-4f26-97c6-35b37926bdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why is Trump in trouble for the \"shithole\" remark when it\\'s only Democrats who claim he did it?',\n",
       " 'Would I have a chance of getting an internship in the U.S. Senate if I have a 2.96 GPA?',\n",
       " 'Do students at schools like Princeton, Columbia, Yale, Harvard and Stanford wear designer brands? How do less wealthy students react?',\n",
       " 'Where can I get quick notifications about UPSC 2018?',\n",
       " 'How is the job security right now of BTA, joining from TCS with 2.5 years of experience, down the line in Deloitte USI (consulting)?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question_text'].tolist()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49a3d4d1-f161-4675-abdd-326a71bf2755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f9da89-2b78-4e71-bcf8-61c7d2bc2138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.9365\n",
       "1    0.0635\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2371810a-a374-48f8-a301-200cb366aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.25, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "141a3460-536f-4e36-a5d8-bcd25f53b006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 4), (2500, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebefb2c9-15f9-498f-b02c-c49416a4c7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>822748</td>\n",
       "      <td>a13799d4fced124bde34</td>\n",
       "      <td>What does the bass mean in a song?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>240478</td>\n",
       "      <td>2f0a9acfbdb7045b7d86</td>\n",
       "      <td>How do I invest £50000 in the best way possible?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6698</th>\n",
       "      <td>68519</td>\n",
       "      <td>0d71093a7abb9e5e1fba</td>\n",
       "      <td>I’ve heard ministers make inside jokes about t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9805</th>\n",
       "      <td>332284</td>\n",
       "      <td>4122f78885c053dcae07</td>\n",
       "      <td>What are the best ways to smoke a boneless tur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>147551</td>\n",
       "      <td>1cdc4872bd2f52aa3fbd</td>\n",
       "      <td>What are some good speech topics for grade 12?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                   qid  \\\n",
       "4901      822748  a13799d4fced124bde34   \n",
       "4375      240478  2f0a9acfbdb7045b7d86   \n",
       "6698       68519  0d71093a7abb9e5e1fba   \n",
       "9805      332284  4122f78885c053dcae07   \n",
       "1101      147551  1cdc4872bd2f52aa3fbd   \n",
       "\n",
       "                                          question_text  target  \n",
       "4901                 What does the bass mean in a song?       0  \n",
       "4375   How do I invest £50000 in the best way possible?       0  \n",
       "6698  I’ve heard ministers make inside jokes about t...       0  \n",
       "9805  What are the best ways to smoke a boneless tur...       0  \n",
       "1101     What are some good speech topics for grade 12?       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698a8be5-8f9e-4bfc-940b-3fc9c80e3ff2",
   "metadata": {},
   "source": [
    "# Simple Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd1c673-2ee5-44dd-9648-7c5c75f0d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b67ef75-6f7d-4011-8e25-da43daaa82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6eb1f82-04c9-43d9-bf34-4c4b2eac1146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "[[2321    0]\n",
      " [ 179    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      2321\n",
      "           1       0.00      0.00      0.00       179\n",
      "\n",
      "    accuracy                           0.93      2500\n",
      "   macro avg       0.46      0.50      0.48      2500\n",
      "weighted avg       0.86      0.93      0.89      2500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arvenka\\AppData\\Local\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arvenka\\AppData\\Local\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arvenka\\AppData\\Local\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "def evaluation_report(gt, pred):\n",
    "    print(confusion_matrix(gt, pred))\n",
    "    print(classification_report(gt, pred))\n",
    "\n",
    "print(\"TEST\")\n",
    "evaluation_report(test['target'], test['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ce16862-c0d2-4314-955b-3262f1eb4898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How can I know if I have internal bleeding in my foot?',\n",
       " 'What was life like in Indonesia during the 80s?',\n",
       " 'Why are there so many remaining vacancies in US federal government \"key jobs\"?',\n",
       " 'Why do my legs get swollen and painful after eating wheat products?',\n",
       " 'What is the difference between US highways and Interstate highways in terms of road and infrastructure quality?',\n",
       " 'What do you think of Teri Hatcher as an actress?',\n",
       " 'Will Ben Sasse likely seek higher officer one day?',\n",
       " 'What causes coulrophobia in a culture?',\n",
       " 'What qualifications are needed to be a room leader in a Preschool Childcare setting?',\n",
       " 'What are important things while creating ERC20 tokens for ICO? After getting tokens in wallet. How do Android and iOS apps are created to link with this wallet?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sincere\n",
    "train[train['target'] == 0].sample(n= 10)['question_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05787218-0ee2-4eb0-9632-ba5cfa78f826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Are anime traps gay?',\n",
       " 'Why do the British get angry at Irish Americans funding the IRA while ignoring the support their security forces gave to loyalist paramilitary groups in Northern Ireland?',\n",
       " 'Do Tamil Nadu girls like to have sex with strangers?',\n",
       " 'On Quora, I get a growing awareness of the USA being increasingly plagued by conservative ignorance and a sense of US exceptionalism (seemingly due to highly efficient propaganda). Can it continue indefinitely, and what would it take to change that?',\n",
       " 'Is the MSM, deep state actors and AstroTurf social media paid recruiters trying hard to impeach a honest President Trump?',\n",
       " 'Is it my imagination or is Mitch McConnell and his cronies walking around with hard-ons now that they are \"in charge\"?',\n",
       " \"Why doesn't the UK realise that the government wanted Brexit and played us via the media, etc. to get the result they wanted?\",\n",
       " 'Is it True that Muslims Refugees in Sweden rape women all the time and the Swedish government ignore there crimes?',\n",
       " 'Why do girls feel so offended when guys look at their bodies when they would most likely look at guys genitals just the same if they were hugged by their cloths like girls clothing does?',\n",
       " 'At what point do American Zionists stop supporting the state of Israel from abroad and make aliyah?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insincere\n",
    "train[train['target'] == 1].sample(n= 10)['question_text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559316dc-a06a-49ce-9a86-3bb071d009bb",
   "metadata": {},
   "source": [
    "# Baseline approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "519022c8-78eb-475c-802b-f3f83a308da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "insincere_intution = ['black', 'trump', 'dumb', 'gays', 'LDS', 'girl', 'blond', 'freak', 'sex', 'bitch', 'dictator', 'lie', 'radical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd2591d3-a642-4f29-ae47-ecefdd00fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_classifier(txt):\n",
    "    #if len(txt.split())< 2:\n",
    "     #   print(txt)\n",
    "      #  return 1\n",
    "\n",
    "    for i in insincere_intution:\n",
    "        if i.lower() in txt.lower():\n",
    "            return 1\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73adf49a-7341-408a-9891-2a323de83c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_classifier('How can america be great again if we keep on addressing president trump as \"Don the con\"?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a85f0b3-8d1b-4308-b02f-adf2b9c95472",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['baseline_predictions'] = train['question_text'].apply(lambda x:baseline_classifier(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f6f5813-9079-40d1-8145-a73464ad43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['baseline_predictions'] = test['question_text'].apply(lambda x:baseline_classifier(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f96ee84-2077-484c-bd23-76b2aa90a720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baseline_predictions\n",
       "0    7053\n",
       "1     447\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['baseline_predictions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d460da4d-8775-404d-bbe7-907da05bdfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "[[6712  332]\n",
      " [ 341  115]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      7044\n",
      "           1       0.26      0.25      0.25       456\n",
      "\n",
      "    accuracy                           0.91      7500\n",
      "   macro avg       0.60      0.60      0.60      7500\n",
      "weighted avg       0.91      0.91      0.91      7500\n",
      "\n",
      "TESTING\n",
      "[[2208  113]\n",
      " [ 141   38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      2321\n",
      "           1       0.25      0.21      0.23       179\n",
      "\n",
      "    accuracy                           0.90      2500\n",
      "   macro avg       0.60      0.58      0.59      2500\n",
      "weighted avg       0.89      0.90      0.89      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING')\n",
    "evaluation_report(train['target'], train['baseline_predictions'])\n",
    "print('TESTING')\n",
    "evaluation_report(test['target'], test['baseline_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eca20f86-84e4-45a9-a5c3-0d4857a1fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06ae5729-ad28-425b-9233-5a5392edc668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arvenka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\arvenka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "Stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fce189a-bcd0-44bd-bb57-e42b23c6cc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f54e90a-b0d4-4754-8b37-dfb2a6c20044",
   "metadata": {},
   "outputs": [],
   "source": [
    " white_list = ['weren',\n",
    " \"weren't\",\n",
    " 'what',\n",
    " 'when',\n",
    " 'where',\n",
    " 'which',\n",
    "'who',\n",
    " 'whom',\n",
    " 'why',\n",
    " 'will']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5eaff200-0212-4849-978b-cff1b121ec94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(white_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "251f6645-7a60-47f7-a2d0-b164cd8943a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopwords = Stopwords-set(white_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba610962-8660-4b94-8e8b-ce70c6b38695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9372f170-c15a-40d0-85f4-6a7ed9645804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "47965e19-0af1-4ac2-9afe-377b0b247b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "wml = WordNetLemmatizer()\n",
    "def lemmatise(lowercase_word):\n",
    "    lemma = []\n",
    "    for word in lowercase_word:\n",
    "        tokens = wml.lemmatize(word)\n",
    "        lemma.append(tokens)\n",
    "    return lemma\n",
    "\n",
    "ps = PorterStemmer()\n",
    "def stemming(lw):\n",
    "    stems = []\n",
    "    for word in lw:\n",
    "        tokens = ps.stem(word)\n",
    "        stems.append(tokens)\n",
    "    return stems\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "da58bd7a-9fef-4be0-b995-3a9f36283fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning_pipeline(text, stopwords, compression_technique='stem'):\n",
    "    #lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    #remove punctuations\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    #tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    #tokens\n",
    "    tokens = [i for i in tokens if i not in stopwords]\n",
    "\n",
    "    # Text standardization\n",
    "    if compression_technique == 'stem':\n",
    "        tokens = stemming(tokens)\n",
    "    else:\n",
    "        tokens = lemmatise(tokens)\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5575a042-2f1e-404d-bde2-349be59409f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What does the bass mean in a song?'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['question_text'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7084e529-af3c-42f0-9a77-38fc75f7e319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['professor', 'tyron', 'hay', 'prove', 'homosexu', 'genet', 'disord']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaning_pipeline(train['question_text'].tolist()[10], Stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8558f82e-ed16-488b-98ac-358178b0f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['question_text_cleaned'] = train['question_text'].apply(data_cleaning_pipeline, args=(Stopwords,))\n",
    "test['question_text_cleaned'] = test['question_text'].apply(data_cleaning_pipeline, args=(Stopwords,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2e655afc-1988-4b47-817d-5bfb66943654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>baseline_predictions</th>\n",
       "      <th>question_text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>822748</td>\n",
       "      <td>a13799d4fced124bde34</td>\n",
       "      <td>What does the bass mean in a song?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[bass, mean, song]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>240478</td>\n",
       "      <td>2f0a9acfbdb7045b7d86</td>\n",
       "      <td>How do I invest £50000 in the best way possible?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[invest, 50000, best, way, possibl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6698</th>\n",
       "      <td>68519</td>\n",
       "      <td>0d71093a7abb9e5e1fba</td>\n",
       "      <td>I’ve heard ministers make inside jokes about t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ive, heard, minist, make, insid, joke, peopl,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9805</th>\n",
       "      <td>332284</td>\n",
       "      <td>4122f78885c053dcae07</td>\n",
       "      <td>What are the best ways to smoke a boneless tur...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[best, way, smoke, boneless, turkey, breast]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>147551</td>\n",
       "      <td>1cdc4872bd2f52aa3fbd</td>\n",
       "      <td>What are some good speech topics for grade 12?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[good, speech, topic, grade, 12]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                   qid  \\\n",
       "4901      822748  a13799d4fced124bde34   \n",
       "4375      240478  2f0a9acfbdb7045b7d86   \n",
       "6698       68519  0d71093a7abb9e5e1fba   \n",
       "9805      332284  4122f78885c053dcae07   \n",
       "1101      147551  1cdc4872bd2f52aa3fbd   \n",
       "\n",
       "                                          question_text  target  \\\n",
       "4901                 What does the bass mean in a song?       0   \n",
       "4375   How do I invest £50000 in the best way possible?       0   \n",
       "6698  I’ve heard ministers make inside jokes about t...       0   \n",
       "9805  What are the best ways to smoke a boneless tur...       0   \n",
       "1101     What are some good speech topics for grade 12?       0   \n",
       "\n",
       "      baseline_predictions                              question_text_cleaned  \n",
       "4901                     0                                 [bass, mean, song]  \n",
       "4375                     0                [invest, 50000, best, way, possibl]  \n",
       "6698                     1  [ive, heard, minist, make, insid, joke, peopl,...  \n",
       "9805                     0       [best, way, smoke, boneless, turkey, breast]  \n",
       "1101                     0                   [good, speech, topic, grade, 12]  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f5df7-e14c-485c-b3a1-234a56d8004a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
